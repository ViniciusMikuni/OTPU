{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43696561-d24c-49a4-99f9-92360e1b244d",
   "metadata": {},
   "source": [
    "# We are going to setup TOTAL using a simplified example based on the datasets from the PUMML publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31028236-bce2-452f-8c24-51005b10d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
    "import horovod.tensorflow.keras as hvd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import argparse\n",
    "import h5py as h5\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from ABCNet import ABCNet, SWD\n",
    "hvd.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbc85fc7-2028-496b-a47a-6ef2a4fc43e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading datasets and applying a simple preprocessing\n",
    "config_file = 'config_dev.json' #store some training info\n",
    "dataset_config = utils.LoadJson(config_file)\n",
    "NSWD = dataset_config['NSWD'] #SWD is calculated considering only NSWD features\n",
    "NPART=dataset_config['NPART'] #maximum number of particles considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c6ad91-301c-4d02-87f4-7103060c1b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-28 11:56:55.775250: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-28 11:56:57.628148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38277 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0\n",
      "2023-01-28 11:56:57.629413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38277 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:41:00.0, compute capability: 8.0\n",
      "2023-01-28 11:56:57.631390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38277 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:82:00.0, compute capability: 8.0\n",
      "2023-01-28 11:56:57.632611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38277 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c1:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "data,label,_ = utils.preprocessing(os.path.join('/global/cfs/cdirs/m3246/vmikuni/PU',dataset_config['FILES']),nparts=NPART)\n",
    "frac = 0.8 #fraction of events used for training\n",
    "data_size = data.shape[0]\n",
    "data_label = data[:,:,:NSWD].copy() #data with pileup used in the loss function to compare with label; the data without pileup\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data,np.concatenate([data_label,label[:,:,:NSWD]],-1)))\n",
    "train_data, test_data = utils.split_data(dataset,data_size,frac)\n",
    "del dataset, data, label, data_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4884f2e-b5a4-48d3-93b2-b80b01db368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = dataset_config['BATCH']\n",
    "LR = float(dataset_config['LR'])\n",
    "NUM_EPOCHS = dataset_config['MAXEPOCH']\n",
    "EARLY_STOP = dataset_config['EARLYSTOP']\n",
    "checkpoint_folder = 'checkpoints_{}/checkpoint'.format(dataset_config['CHECKPOINT_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "260f6e32-8acc-41fd-9e07-cff451300086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1000, 6)]    0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 1000, 3)     0           ['input_1[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4 (Sl  (None, 1000, 2)     0           ['tf.__operators__.getitem_3[0][0\n",
      " icingOpLambda)                                                  ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose (TFOpLa  (None, 2, 1000)     0           ['tf.__operators__.getitem_4[0][0\n",
      " mbda)                                                           ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5 (Sl  (None, 1, 1000)     0           ['tf.compat.v1.transpose[0][0]'] \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.tile (TFOpLambda)           (None, 1000, 1000)   0           ['tf.__operators__.getitem_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 1000)        0           ['input_1[0][0]']                \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 1000)        0           ['input_1[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 1000)        0           ['input_1[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_1 (TFOp  (None, 1000, 1000)  0           ['tf.tile[0][0]']                \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.eq (TFOpLambd  (None, 1000)        0           ['tf.__operators__.getitem[0][0]'\n",
      " a)                                                              ]                                \n",
      "                                                                                                  \n",
      " tf.ones_like (TFOpLambda)      (None, 1000)         0           ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.zeros_like (TFOpLambda)     (None, 1000)         0           ['tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.square (TFOpLambda)    (None, 1000, 2)      0           ['tf.__operators__.getitem_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 1000, 1000)   0           ['tf.tile[0][0]',                \n",
      "                                                                  'tf.compat.v1.transpose_1[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.where (TFOpLambda)          (None, 1000)         0           ['tf.__operators__.eq[0][0]',    \n",
      "                                                                  'tf.ones_like[0][0]',           \n",
      "                                                                  'tf.zeros_like[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  (None, 1000, 1)     0           ['tf.math.square[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.abs (TFOpLambda)       (None, 1000, 1000)   0           ['tf.math.subtract[0][0]']       \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 1000, 1)      0           ['tf.where[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_2 (TFOp  (None, 1, 1000)     0           ['tf.math.reduce_sum[0][0]']     \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.linalg.matmul (TFOpLambda)  (None, 1000, 1000)   0           ['tf.__operators__.getitem_4[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'tf.compat.v1.transpose[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.abs_1 (TFOpLambda)     (None, 1000, 1000)   0           ['tf.math.abs[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 1000, 1)     0           ['tf.expand_dims[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 1000, 1000)  0           ['tf.math.reduce_sum[0][0]',     \n",
      " da)                                                              'tf.compat.v1.transpose_2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 1000, 1000)   0           ['tf.linalg.matmul[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.greater_equal (TFOpLam  (None, 1000, 1000)  0           ['tf.math.abs_1[0][0]']          \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None, 1000, 1000)  0           ['tf.math.abs[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_3 (TFOp  (None, 1, 1000)     0           ['tf.math.multiply_1[0][0]']     \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 1000, 1000)  0           ['tf.__operators__.add[0][0]',   \n",
      " mbda)                                                            'tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.square_1 (TFOpLambda)  (None, 1000, 1000)   0           ['tf.math.abs[0][0]']            \n",
      "                                                                                                  \n",
      " tf.where_1 (TFOpLambda)        (None, 1000, 1000)   0           ['tf.math.greater_equal[0][0]',  \n",
      "                                                                  'tf.math.subtract_1[0][0]',     \n",
      "                                                                  'tf.math.abs[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 1000, 1000)  0           ['tf.compat.v1.transpose_3[0][0]'\n",
      " mbda)                                                           , 'tf.math.multiply_1[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.subtract_2 (TFOpLambda  (None, 1000, 1000)  0           ['tf.__operators__.add_1[0][0]', \n",
      " )                                                                'tf.math.square_1[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.square_2 (TFOpLambda)  (None, 1000, 1000)   0           ['tf.where_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.equal (TFOpLambda)     (None, 1000, 1000)   0           ['tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.zeros_like_1 (TFOpLambda)   (None, 1000, 1000)   0           ['tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 1000, 1000)  0           ['tf.math.subtract_2[0][0]',     \n",
      " mbda)                                                            'tf.math.square_2[0][0]']       \n",
      "                                                                                                  \n",
      " tf.where_2 (TFOpLambda)        (None, 1000, 1000)   0           ['tf.math.equal[0][0]',          \n",
      "                                                                  'tf.zeros_like_1[0][0]',        \n",
      "                                                                  'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 1000, 1000)  0           ['tf.__operators__.add_2[0][0]', \n",
      " mbda)                                                            'tf.where_2[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.negative (TFOpLambda)  (None, 1000, 1000)   0           ['tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.top_k (TFOpLambda)     TopKV2(values=(None  0           ['tf.math.negative[0][0]']       \n",
      "                                , 1000, 50),                                                      \n",
      "                                 indices=(None, 100                                               \n",
      "                                0, 50))                                                           \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather (TFOpLambd  (None, 1000, 4)     0           ['input_1[0][0]']                \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " Gap1 (GAPBlock)                ((None, 1000, 16),   330         ['tf.math.top_k[0][1]',          \n",
      "                                 (None, 1000, 16),                'tf.compat.v1.gather[0][0]',    \n",
      "                                 (None, 1000, 1))                 'tf.where[0][0]',               \n",
      "                                                                  'tf.math.top_k[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1000, 64)     1088        ['Gap1[0][0]']                   \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 1000, 64)     4160        ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 1000, 64)    256         ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " Gap2 (GAPBlock)                ((None, 1000, 32),   4458        ['tf.math.top_k[0][1]',          \n",
      "                                 (None, 1000, 32),                'batch_normalization_4[0][0]',  \n",
      "                                 (None, 1000, 1))                 'tf.where[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 1000, 128)    4224        ['Gap2[0][0]']                   \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 1000, 128)    16512       ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 1000, 128)   512         ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 1000, 240)    0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  'batch_normalization_9[0][0]',  \n",
      "                                                                  'Gap1[0][1]',                   \n",
      "                                                                  'Gap2[0][1]']                   \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 1000, 256)    61696       ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 1000, 256)   1024        ['conv1d_4[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  (None, 1, 256)      0           ['batch_normalization_10[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.tile_1 (TFOpLambda)         (None, 1000, 256)    0           ['tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)       (None, 1000, 512)    0           ['tf.tile_1[0][0]',              \n",
      "                                                                  'batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 1000, 128)    65664       ['tf.concat_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 1000, 1)      129         ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 160,053\n",
      "Trainable params: 158,957\n",
      "Non-trainable params: 1,096\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-28 11:57:03.100933: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 10s 634ms/step - loss: 148.1756 - val_loss: 445.8336 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 3s 548ms/step - loss: 11.8825 - val_loss: 416.9179 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 9.4551 - val_loss: 388.4260 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 3s 547ms/step - loss: 8.0548 - val_loss: 368.8071 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 3s 546ms/step - loss: 7.0948 - val_loss: 349.5662 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 6.6497 - val_loss: 329.9316 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 3s 546ms/step - loss: 6.2904 - val_loss: 322.3268 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 6.1170 - val_loss: 306.6929 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 5.8217 - val_loss: 302.3495 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 5.8882 - val_loss: 295.9363 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 5.6915 - val_loss: 282.8261 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 5.6289 - val_loss: 276.9536 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 5.6194 - val_loss: 267.0872 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 5.4662 - val_loss: 258.9312 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 5.4508 - val_loss: 254.7817 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 3s 543ms/step - loss: 5.2767 - val_loss: 246.2961 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 5.1893 - val_loss: 241.1980 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 5.1952 - val_loss: 235.7311 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 5.0687 - val_loss: 229.4346 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 5.1460 - val_loss: 219.8116 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 3s 546ms/step - loss: 4.9553 - val_loss: 211.1588 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 4.9486 - val_loss: 211.2993 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 5.0160 - val_loss: 204.8880 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 4.8272 - val_loss: 205.4850 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 4.8485 - val_loss: 196.8664 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 3s 565ms/step - loss: 4.7726 - val_loss: 189.8392 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 4.7184 - val_loss: 189.0401 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 4.7730 - val_loss: 186.8228 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 4.6482 - val_loss: 177.8292 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 4.6612 - val_loss: 170.2624 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 4.6165 - val_loss: 166.7035 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 4.5109 - val_loss: 166.2101 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 4.5338 - val_loss: 160.6509 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 4.5617 - val_loss: 154.5834 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 4.4389 - val_loss: 143.4062 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 4.5281 - val_loss: 136.9949 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 4.4058 - val_loss: 134.1718 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 4.3541 - val_loss: 126.7165 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 4.2242 - val_loss: 117.2651 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 4.2326 - val_loss: 111.4167 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 4.1494 - val_loss: 108.7439 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 4.1106 - val_loss: 98.8217 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 4.2190 - val_loss: 94.7889 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 4.0402 - val_loss: 88.4536 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 4.0637 - val_loss: 82.6400 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 3s 551ms/step - loss: 4.0458 - val_loss: 79.7407 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 3s 543ms/step - loss: 4.0358 - val_loss: 70.4798 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 4.0471 - val_loss: 63.6866 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 3s 547ms/step - loss: 3.9619 - val_loss: 60.1259 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 3.9687 - val_loss: 55.9280 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 3.9977 - val_loss: 49.0282 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 3.9254 - val_loss: 41.7645 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 3.8714 - val_loss: 38.3945 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 3s 549ms/step - loss: 3.9603 - val_loss: 34.5710 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 3.8157 - val_loss: 32.6334 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 3.8939 - val_loss: 29.1252 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 3.8103 - val_loss: 26.1532 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 3.8128 - val_loss: 23.1368 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 3.7467 - val_loss: 20.6182 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 3.5831 - val_loss: 16.6566 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 3.5893 - val_loss: 13.5172 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 3.4763 - val_loss: 11.4019 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 3s 546ms/step - loss: 3.5205 - val_loss: 11.1348 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 3.5120 - val_loss: 10.2069 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 3.5384 - val_loss: 9.7493 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 3s 550ms/step - loss: 3.4405 - val_loss: 8.7478 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 3.5288 - val_loss: 8.0737 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 3s 546ms/step - loss: 3.5165 - val_loss: 7.5646 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 3.6124 - val_loss: 7.6899 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 3.5466 - val_loss: 6.8908 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 3s 551ms/step - loss: 3.4145 - val_loss: 6.7536 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 3s 546ms/step - loss: 3.4326 - val_loss: 6.4797 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 3s 546ms/step - loss: 3.2848 - val_loss: 6.0588 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 3.3742 - val_loss: 6.1467 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.3366 - val_loss: 6.1041 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 3.3317 - val_loss: 5.8576 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 3.3153 - val_loss: 5.6892 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.2870 - val_loss: 6.1339 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.3171 - val_loss: 5.7100 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.2585 - val_loss: 6.1385 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 3.1997 - val_loss: 5.6344 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 3s 547ms/step - loss: 3.2432 - val_loss: 5.4795 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.2424 - val_loss: 5.9042 - lr: 0.0010\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.3146 - val_loss: 5.6223 - lr: 0.0010\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.2450 - val_loss: 5.5805 - lr: 0.0010\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.2395 - val_loss: 5.5427 - lr: 0.0010\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 3.2520 - val_loss: 5.6073 - lr: 0.0010\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.2260 - val_loss: 5.5225 - lr: 0.0010\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 3.1829 - val_loss: 5.1213 - lr: 0.0010\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.2271 - val_loss: 6.2716 - lr: 0.0010\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 3.3092 - val_loss: 5.3344 - lr: 0.0010\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 3s 535ms/step - loss: 3.2248 - val_loss: 5.7063 - lr: 0.0010\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.2299 - val_loss: 6.0417 - lr: 0.0010\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.1995 - val_loss: 5.5273 - lr: 0.0010\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 3.1342 - val_loss: 5.5696 - lr: 0.0010\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 3.1740 - val_loss: 5.2733 - lr: 0.0010\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 3s 535ms/step - loss: 3.1661 - val_loss: 5.6377 - lr: 0.0010\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 3s 548ms/step - loss: 3.3683 - val_loss: 5.1157 - lr: 0.0010\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.1814 - val_loss: 5.8368 - lr: 0.0010\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.2680 - val_loss: 5.5892 - lr: 0.0010\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 3.1957 - val_loss: 4.4711 - lr: 0.0010\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.2493 - val_loss: 4.5955 - lr: 0.0010\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 3.2810 - val_loss: 4.1924 - lr: 0.0010\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.2521 - val_loss: 5.0279 - lr: 0.0010\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.2548 - val_loss: 4.3908 - lr: 0.0010\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 3s 546ms/step - loss: 3.2210 - val_loss: 4.1691 - lr: 0.0010\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.1313 - val_loss: 5.0958 - lr: 0.0010\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.1217 - val_loss: 4.2517 - lr: 0.0010\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.2244 - val_loss: 4.7936 - lr: 0.0010\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 3.2317 - val_loss: 5.0497 - lr: 0.0010\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.1234 - val_loss: 4.3562 - lr: 0.0010\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 3s 532ms/step - loss: 3.1466 - val_loss: 4.2657 - lr: 0.0010\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 3.1717 - val_loss: 3.8216 - lr: 0.0010\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 3s 551ms/step - loss: 3.1244 - val_loss: 3.2418 - lr: 0.0010\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 3.1022 - val_loss: 3.5040 - lr: 0.0010\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 3.0847 - val_loss: 3.6899 - lr: 0.0010\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.0869 - val_loss: 3.6176 - lr: 0.0010\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 3.0757 - val_loss: 3.5230 - lr: 0.0010\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 3.1584 - val_loss: 3.6128 - lr: 0.0010\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.1413 - val_loss: 3.9089 - lr: 0.0010\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 3.1468 - val_loss: 3.3615 - lr: 0.0010\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.1032 - val_loss: 3.4448 - lr: 0.0010\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.0764 - val_loss: 3.3577 - lr: 0.0010\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - ETA: 0s - loss: 3.0235\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.0235 - val_loss: 3.4412 - lr: 0.0010\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 2.9854 - val_loss: 3.1487 - lr: 1.0000e-04\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.0173 - val_loss: 3.3464 - lr: 1.0000e-04\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 3s 532ms/step - loss: 3.0226 - val_loss: 3.3326 - lr: 1.0000e-04\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 2.9973 - val_loss: 3.1022 - lr: 1.0000e-04\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9531 - val_loss: 3.1757 - lr: 1.0000e-04\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9578 - val_loss: 3.1835 - lr: 1.0000e-04\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 3.0034 - val_loss: 3.0556 - lr: 1.0000e-04\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9530 - val_loss: 3.1429 - lr: 1.0000e-04\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.9825 - val_loss: 3.1909 - lr: 1.0000e-04\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.9672 - val_loss: 3.1876 - lr: 1.0000e-04\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 3.0207 - val_loss: 2.9829 - lr: 1.0000e-04\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.9271 - val_loss: 3.0333 - lr: 1.0000e-04\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 3s 532ms/step - loss: 2.9490 - val_loss: 3.0540 - lr: 1.0000e-04\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9938 - val_loss: 3.0398 - lr: 1.0000e-04\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 2.8602 - val_loss: 2.8492 - lr: 1.0000e-04\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 3.0206 - val_loss: 3.0615 - lr: 1.0000e-04\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9054 - val_loss: 2.9989 - lr: 1.0000e-04\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9985 - val_loss: 3.0654 - lr: 1.0000e-04\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9128 - val_loss: 2.9896 - lr: 1.0000e-04\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.8873 - val_loss: 3.2450 - lr: 1.0000e-04\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9519 - val_loss: 2.9182 - lr: 1.0000e-04\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 3s 532ms/step - loss: 2.9785 - val_loss: 3.1282 - lr: 1.0000e-04\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9679 - val_loss: 3.0398 - lr: 1.0000e-04\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 3s 532ms/step - loss: 2.9354 - val_loss: 3.1440 - lr: 1.0000e-04\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.9187\n",
      "Epoch 149: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.9187 - val_loss: 3.0804 - lr: 1.0000e-04\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9374 - val_loss: 3.1785 - lr: 1.0000e-05\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.8866 - val_loss: 3.0128 - lr: 1.0000e-05\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9418 - val_loss: 2.9609 - lr: 1.0000e-05\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9374 - val_loss: 3.1509 - lr: 1.0000e-05\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 2.9207 - val_loss: 2.7919 - lr: 1.0000e-05\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.9016 - val_loss: 2.8210 - lr: 1.0000e-05\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9516 - val_loss: 2.9957 - lr: 1.0000e-05\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.9131 - val_loss: 2.9781 - lr: 1.0000e-05\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.9934 - val_loss: 3.0403 - lr: 1.0000e-05\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9351 - val_loss: 2.8212 - lr: 1.0000e-05\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 3.0229 - val_loss: 2.8826 - lr: 1.0000e-05\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9307 - val_loss: 2.9532 - lr: 1.0000e-05\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9108 - val_loss: 2.8342 - lr: 1.0000e-05\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.9444 - val_loss: 2.8492 - lr: 1.0000e-05\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.9305\n",
      "Epoch 164: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9305 - val_loss: 2.9531 - lr: 1.0000e-05\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9496 - val_loss: 2.9328 - lr: 1.0000e-06\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.9977 - val_loss: 2.9418 - lr: 1.0000e-06\n",
      "Epoch 167/200\n",
      "6/6 [==============================] - 3s 535ms/step - loss: 2.8806 - val_loss: 2.9694 - lr: 1.0000e-06\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 3s 532ms/step - loss: 2.9079 - val_loss: 2.8402 - lr: 1.0000e-06\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9474 - val_loss: 3.0399 - lr: 1.0000e-06\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.9111 - val_loss: 2.8946 - lr: 1.0000e-06\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.9605 - val_loss: 2.9380 - lr: 1.0000e-06\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 3s 546ms/step - loss: 2.9806 - val_loss: 2.7871 - lr: 1.0000e-06\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 2.9285 - val_loss: 2.7754 - lr: 1.0000e-06\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9012 - val_loss: 2.9211 - lr: 1.0000e-06\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 2.9693 - val_loss: 2.7382 - lr: 1.0000e-06\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.9108 - val_loss: 2.7563 - lr: 1.0000e-06\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9832 - val_loss: 2.9761 - lr: 1.0000e-06\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.9043 - val_loss: 3.0235 - lr: 1.0000e-06\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.9378 - val_loss: 2.8868 - lr: 1.0000e-06\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9268 - val_loss: 2.9656 - lr: 1.0000e-06\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.8797 - val_loss: 2.9412 - lr: 1.0000e-06\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 3.0090 - val_loss: 2.9727 - lr: 1.0000e-06\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.8791 - val_loss: 2.9907 - lr: 1.0000e-06\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 3s 535ms/step - loss: 2.9350 - val_loss: 3.0901 - lr: 1.0000e-06\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.9289\n",
      "Epoch 185: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.9289 - val_loss: 3.1203 - lr: 1.0000e-06\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.9314 - val_loss: 3.0175 - lr: 1.0000e-07\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.8874 - val_loss: 2.7839 - lr: 1.0000e-07\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9080 - val_loss: 2.8932 - lr: 1.0000e-07\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.9598 - val_loss: 3.0836 - lr: 1.0000e-07\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9608 - val_loss: 2.8243 - lr: 1.0000e-07\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9283 - val_loss: 2.9199 - lr: 1.0000e-07\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 3s 535ms/step - loss: 2.9754 - val_loss: 2.8562 - lr: 1.0000e-07\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 2.8996 - val_loss: 2.9054 - lr: 1.0000e-07\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 2.9002 - val_loss: 2.8320 - lr: 1.0000e-07\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.9326\n",
      "Epoch 195: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "6/6 [==============================] - 3s 535ms/step - loss: 2.9326 - val_loss: 2.9921 - lr: 1.0000e-07\n"
     ]
    }
   ],
   "source": [
    "inputs,outputs = ABCNet(npoint=NPART,nfeat=dataset_config['SHAPE'][2])\n",
    "model = Model(inputs=inputs,outputs=outputs)\n",
    "opt = keras.optimizers.Adam(learning_rate=LR)\n",
    "opt = hvd.DistributedOptimizer(\n",
    "    opt, average_aggregated_gradients=True)\n",
    "model.compile(loss=SWD,\n",
    "              optimizer=opt,experimental_run_tf_function=False)\n",
    "    \n",
    "callbacks = [\n",
    "    hvd.callbacks.BroadcastGlobalVariablesCallback(0),\n",
    "    hvd.callbacks.MetricAverageCallback(),            \n",
    "    ReduceLROnPlateau(patience=10, \n",
    "                      min_lr=1e-8,verbose=hvd.rank()==0),\n",
    "    EarlyStopping(patience=EARLY_STOP,restore_best_weights=True),\n",
    "    ]\n",
    "\n",
    "if hvd.rank()==0:\n",
    "    checkpoint = ModelCheckpoint(checkpoint_folder,save_best_only=True,mode='auto',\n",
    "                                 period=1,save_weights_only=True)\n",
    "        \n",
    "    callbacks.append(checkpoint)\n",
    "    print(model.summary())\n",
    "    \n",
    "load=False\n",
    "if load:\n",
    "    model.load_weights(checkpoint_folder)\n",
    "else:\n",
    "    history = model.fit(\n",
    "        train_data.batch(BATCH_SIZE),\n",
    "        epochs=NUM_EPOCHS,\n",
    "        steps_per_epoch=int(data_size*frac/BATCH_SIZE),\n",
    "        # steps_per_epoch=1,\n",
    "        validation_data=test_data.batch(BATCH_SIZE),\n",
    "        validation_steps=int(data_size*(1-frac)/BATCH_SIZE),\n",
    "        verbose=1 if hvd.rank()==0 else 0,\n",
    "        callbacks=callbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef6f436-3f76-4e1d-9728-561b3882216f",
   "metadata": {},
   "source": [
    "# Let's plot the jet pt resolution and compare with PUPPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f889206-8fa1-498c-9e20-b2dca4b6b0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 151ms/step\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)\n",
    "data,nopu,jet_info = utils.preprocessing(os.path.join('/global/cfs/cdirs/m3246/vmikuni/PU',dataset_config['FILES']),nparts=NPART)\n",
    "total_weights = model.predict(data,batch_size=200)\n",
    "puppi_weights = np.expand_dims(data[:,:,4],-1)\n",
    "data = utils.convert_preprocessing(data) #undo data preprocessing to calculate jet resolution\n",
    "nopu = utils.convert_preprocessing(nopu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaa1260e-d5f1-4c82-867f-b8633375f5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 39.,  28.,  64.,  61.,  54., 105., 107., 126.,  99., 140., 156.,\n",
       "        168., 170., 174., 147., 103.,  82.,  47.,  37.]),\n",
       " array([100., 110., 120., 130., 140., 150., 160., 170., 180., 190., 200.,\n",
       "        210., 220., 230., 240., 250., 260., 270., 280., 290.]),\n",
       " <BarContainer object of 19 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Look only at the leading jet for simplicity\n",
    "mask_jet1 = jet_info==0\n",
    "px,py,pz=utils.convert_coordinate(nopu[:,:,:4],mask_jet1)\n",
    "\n",
    "jet_pt_truth = np.sum(np.sqrt(px**2+py**2),1)[:,0]\n",
    "plt.hist(jet_pt_truth,bins=np.arange(100, 300, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "895859f9-599a-4057-a608-d5626a72d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "px,py,pz=utils.convert_coordinate(data[:,:,:4],mask_jet1)\n",
    "jet_pt_total = np.sum(np.sqrt(px**2+py**2)*(total_weights),1)[:,0]\n",
    "jet_pt_puppi = np.sum(np.sqrt(px**2+py**2)*(puppi_weights),1)[:,0]\n",
    "res_total = 100*(jet_pt_truth-jet_pt_total)/jet_pt_truth\n",
    "res_puppi = 100*(jet_pt_truth-jet_pt_puppi)/jet_pt_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "380b2dd4-645a-4499-a0d3-7190146d354b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "binning = np.linspace(-10,10,20)\n",
    "\n",
    "label_names = {\n",
    "        'puppi': 'puppi',\n",
    "        'abc': 'total',\n",
    "}\n",
    "feed_dict = {\n",
    "        'puppi': res_puppi,\n",
    "        'abc': res_total,\n",
    "}\n",
    "\n",
    "fig,ax0 = utils.HistRoutine(feed_dict,xlabel=r'Percent jet $p_T$ resolution',\n",
    "                            ylabel= 'Normalized entries',plot_ratio=False,binning=binning,\n",
    "                            label_names=label_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d911334-3cb5-4445-901a-7012aac19261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.9.0",
   "language": "python",
   "name": "tensorflow-2.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
